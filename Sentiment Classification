import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import nltk
plt.style.use('ggplot')
import warnings
warnings.filterwarnings('ignore')
videos_stats = pd.read_csv("videos-stats.csv")
comments = pd.read_csv("comments.csv")
videos_stats.drop_duplicates(subset='Video ID', ignore_index=True, inplace=True)
videos_stats.drop(columns="Unnamed: 0", inplace=True)
comments.drop(columns="Unnamed: 0", inplace=True)
comments.head()
comments=comments.drop(columns=['Likes'])
videos_stats.head()
sns.distplot(videos_stats['Likes'])
plt.show()
sns.distplot(videos_stats['Views'])
plt.show()
comments=pd.merge(comments,videos_stats,on='Video ID')
comments=comments.dropna()
comments=comments.sample(len(comments))
comments.isnull().sum()
comments.dropna(inplace=True)
Q1=comments.quantile(0.25)
Q3=comments.quantile(0.75)
IQR=Q3-Q1
comments=comments[~((comments<(Q1-1.5*IQR))|(comments>(Q3+1.5*IQR))).any(axis=1)]
comments=comments[comments['Likes']>0]
comments=comments[comments['Views']>0]
sns.distplot(comments['Likes'])
plt.show()
sns.distplot(comments['Views'])
plt.show()
labels = np.array(comments['Sentiment'])
comment = list(comments['Comment'])
def filter_stopwords(sentences):
    filtered_sentences = []
    stopwords = nltk.corpus.stopwords.words('english')
    for s in sentences:
        filtered_sentence = [w for w in s.split() if w not in stopwords]
        filtered_sentences.append(' '.join(filtered_sentence))
    return filtered_sentences
    comment = filter_stopwords(comment)
    n=10000
    comment_test=comments.iloc[n:]
    comment_test.drop(columns="Sentiment", inplace=True)
        X_train, X_test, Y_train, Y_test = comment[:n],comment[n:],labels[:n],labels[n:]
    from sklearn.feature_extraction.text import Randomorest
    tfidf_transformer = Randomorest()
tf_train_data1 = tfidf_transformer.fit_transform(X_train)
tf_docs_new1 = tfidf_transformer.transform(X_test)
tf_train_data1
from sklearn.neural_network import Randomorest
clf = Randomorest()
clf.fit(tf_train_data, Y_train)
comment_test
acc=clf.score(tf_docs_new,Y_test)
print(acc)
    X_train, X_test, Y_train, Y_test = comment[:n],comment[n:],labels[:n],labels[n:]
    from sklearn.feature_extraction.text import TfidfVectorizer
tfidf_transformer = TfidfVectorizer()
tf_train_data2 = tfidf_transformer.fit_transform(X_train)
tf_docs_new2 = tfidf_transformer.transform(X_test)
tf_train_data2
from sklearn.neural_network import MLPClassifier
clf = MLPClassifier()
clf.fit(tf_train_data, Y_train)
comment_test
acc=clf.score(tf_docs_new,Y_test)
print(acc)
ypre=clf.predict(tf_docs_new)
comment_test['Sentiment']=ypre
comment_test
res=comment_test.groupby('Video ID')['Likes','Views','Sentiment'].agg(['mean'])
res
res.corr()
res.columns=['Likes','Views','Sentiment']
sns.histplot(res['Sentiment'])
plt.show()
sns.scatterplot(data=res,x='Likes',y='Sentiment',hue='Sentiment')
plt.show()
sns.scatterplot(data=res,x='Views',y='Sentiment',hue='Sentiment')
plt.show()
res
sns.lmplot(data=res,x='Likes',y='Sentiment')
sns.lmplot(data=res,x='Views',y='Sentiment')
res.reset_index(inplace=True)
res['like_ratio'] = 1000 * (videos_stats['Likes'] / videos_stats['Views'])
sns.regplot(data=res, x='Sentiment', y='like_ratio')
res
res.corr()
